{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9256957f-1f9d-4af5-8f57-cc46832c4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, LineString, MultiLineString, MultiPolygon\n",
    "from shapely import distance, from_wkt, intersects, buffer, set_precision, shortest_line\n",
    "from shapely.ops import split, snap, transform, nearest_points\n",
    "from functools import partial\n",
    "import pyproj\n",
    "from itertools import chain\n",
    "import ast\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8ed663aa-0da9-47ce-b72d-8305ce0c131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use settings for Lima or London\n",
    "\n",
    "# # Lima\n",
    "\n",
    "# lima = True\n",
    "# crs = 32718\n",
    "\n",
    "# bus_route_path = \"data/bus_routes_lima.geojson\"\n",
    "# stops_path = 'data/stops_lima.txt' # from GTFS files\n",
    "# sequence_path = 'data/lima_stops_seq.csv'\n",
    "# output_path = 'processed_results_lima.csv'\n",
    "\n",
    "# London ~ 15 min calculation time\n",
    "\n",
    "lima = False\n",
    "crs = 32630\n",
    "\n",
    "bus_route_path = \"data/bus_routes_london.geojson\"\n",
    "stops_path = 'data/stops_london.txt' # from GTFS files\n",
    "sequence_path = 'busability/london_stops_seq.csv'\n",
    "output_path = 'processed_results_london.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "db6e2b32-c186-4e9a-a344-d6554c2f618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_line(sline):\n",
    "    buffered_polygon = sline.buffer(1)\n",
    "\n",
    "    # Check if the buffered result is a MultiPolygon and union it to a single Polygon\n",
    "    if isinstance(buffered_polygon, MultiPolygon):\n",
    "        try:\n",
    "            buffered_polygon = buffered_polygon.union()\n",
    "        except:\n",
    "            buffered_polygon = buffered_polygon.geoms[0]\n",
    "\n",
    "\n",
    "    \n",
    "    # Extract the outer ring as a LineString\n",
    "    outer_ring_line = LineString(buffered_polygon.exterior.coords)\n",
    "    return outer_ring_line\n",
    "    \n",
    "# needed for Lima data\n",
    "def modify_string(value):\n",
    "    # Add 'r' at the beginning\n",
    "    value = 'r' + value\n",
    "    \n",
    "    # Replace '_Ida' with 'a' and '_Vuelta' with 'b'\n",
    "    if '_Ida' in value:\n",
    "        value = value.replace('_Ida', 'A')\n",
    "    elif '_Vuelta' in value:\n",
    "        value = value.replace('_Vuelta', 'B')\n",
    "    return value\n",
    "    \n",
    "\n",
    "def add_point(sline, bus_stop_1, bus_stop_2):\n",
    "    \n",
    "    all_points_coords = chain(sline.coords,bus_stop_1.coords,bus_stop_2.coords)\n",
    "    all_points = map(Point, all_points_coords)\n",
    "    new_line = LineString(sorted(all_points, key=line.project))\n",
    "    #new_ls = transform(project, new_line)\n",
    "    return new_line\n",
    "    \n",
    "\n",
    "def clip_busstops(start_point, end_point, slines):\n",
    "    \n",
    "    split1 = split(slines, start_point)\n",
    "    \n",
    "    # Check if the result of the split is a GeometryCollection and iterate over it\n",
    "    if isinstance(split1, (list, tuple)):\n",
    "        segments = split1\n",
    "    else:\n",
    "        segments = [geom for geom in split1.geoms if isinstance(geom, LineString)]\n",
    "    \n",
    "    gdf = gpd.GeoDataFrame(geometry=segments).set_crs(crs)\n",
    "    \n",
    "    split2 = split(MultiLineString(gdf.geometry.tolist()), end_point)\n",
    "    \n",
    "    if isinstance(split2, (list, tuple)):\n",
    "        segments = split2\n",
    "    else:\n",
    "        # It's a GeometryCollection, extract only LineStrings from it\n",
    "        segments = [geom for geom in split2.geoms if isinstance(geom, LineString)]\n",
    "\n",
    "    intersecting_segments = []\n",
    "    \n",
    "    for segment in segments:\n",
    "        if intersects(segment, end_point) and intersects(segment, start_point):\n",
    "            intersecting_segments.append(segment)\n",
    "\n",
    "    if intersecting_segments:\n",
    "        # Find the segment with the shortest length among the intersecting ones\n",
    "        target_segment = min(intersecting_segments, key=lambda s: s.length)\n",
    "        return target_segment\n",
    "    \n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0544c3a2-2f2e-44e1-a737-07a2a063eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_lines = gpd.read_file(bus_route_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "00c5014f-568b-4065-a025-e44d5c985d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stops.txt GTFS file into a DataFrame\n",
    "stops_df = pd.read_csv(stops_path)\n",
    "stops_df = df[[\"stop_id\", \"stop_lon\", \"stop_lat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "82637158-cb52-4db2-be14-eefd0b0baea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to the creation of the Lima dataset it needs a different approach to read the data\n",
    "if lima:\n",
    "    df = pd.read_csv(sequence_path, delimiter=',', header=None,names=['route_id', 'stop_id', \"foo\", \"foo2\", \"foo3\", \"foo4\"], skiprows=1)\n",
    "    df = df.groupby('route_id')[\"stop_id\"].apply(list).reset_index()\n",
    "\n",
    "    df.columns = ['route_id', 'stop_ids']\n",
    "else:\n",
    "    df = pd.read_csv(sequence_path, delimiter=',', header=None, names=['id', 'route_id', 'stop_ids'], skiprows=1)\n",
    "    df['stop_ids'] = df['stop_ids'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "37a492aa-6ef1-4559-9d47-3a7c13988637",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded = df.explode('stop_ids')\n",
    "df_expanded = df_expanded.drop_duplicates()\n",
    "df_expanded['incremental_id'] = df_expanded.groupby('route_id').cumcount()\n",
    "df_expanded.rename(columns={'stop_ids': 'stop_id'}, inplace=True)\n",
    "result_df = pd.merge(df_expanded, stops_df, on='stop_id', how='inner')\n",
    "result_df = result_df[['route_id', 'stop_id', 'stop_lon', 'stop_lat', 'incremental_id']]\n",
    "result_df = result_df.dropna(subset=['route_id'])\n",
    "#result_df['route_id'] = result_df['route_id'].astype(int)\n",
    "df_no_duplicates = result_df.drop_duplicates()\n",
    "df_no_duplicates = df_no_duplicates.sort_values(by=['route_id', 'incremental_id'])\n",
    "df = df_no_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f7a1f944-0fa8-451f-a7c4-bfa3021fca75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a transformer for converting coordinates from EPSG:4326 to your target CRS, e.g., EPSG:3857\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:\" +str(crs), always_xy=True)\n",
    "\n",
    "cnt = 0\n",
    "processed_pairs = set()\n",
    "results = {}\n",
    "\n",
    "def clean_and_convert(value):\n",
    "    try:\n",
    "        value = str(value).strip()\n",
    "        value = re.sub(r'[−–—]', '-', value)\n",
    "        value = re.sub(r'[^0-9.-]', '', value)\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        print(f\"Warning: Unable to convert value '{value}' to float.\")\n",
    "        return None\n",
    "\n",
    "# Loop through each unique route\n",
    "for route in tqdm(df[\"route_id\"].unique(), desc=\"Processing\"):\n",
    "    #print(f\"Processing route: {route}\")\n",
    "    part_df = df[df[\"route_id\"] == route]\n",
    "    points_list = []\n",
    "\n",
    "    try:\n",
    "        line = gdf_lines[gdf_lines[\"route_id\"] == route].geometry.iloc[0]\n",
    "    except:\n",
    "        cnt += 1\n",
    "        continue\n",
    "            \n",
    "\n",
    "    # Loop through each row and the next row with a progress bar\n",
    "    for i in range(len(part_df) - 1):\n",
    "        row1, row2 = part_df.iloc[i], part_df.iloc[i + 1]\n",
    "        \n",
    "        lon1 = clean_and_convert(row1['stop_lon'])\n",
    "        lat1 = clean_and_convert(row1['stop_lat'])\n",
    "        lon2 = clean_and_convert(row2['stop_lon'])\n",
    "        lat2 = clean_and_convert(row2['stop_lat'])\n",
    "\n",
    "    \n",
    "        if lon1 is None or lat1 is None or lon2 is None or lat2 is None:\n",
    "            continue\n",
    "        \n",
    "        # Transform coordinates to the target CRS\n",
    "        x1, y1 = transformer.transform(lon1, lat1)\n",
    "        x2, y2 = transformer.transform(lon2, lat2)\n",
    "\n",
    "    \n",
    "        point1 = Point(x1, y1)\n",
    "        point2 = Point(x2, y2)\n",
    "    \n",
    "        pair_id = (row1['stop_id'], row2['stop_id'], route)\n",
    "    \n",
    "        processed_line = preprocess_line(line)\n",
    "        processed_line = add_point(processed_line, point1, point2)\n",
    "    \n",
    "        if pair_id not in processed_pairs:\n",
    "            result = clip_busstops(point1, point2, processed_line)\n",
    "            results[pair_id] = result\n",
    "            processed_pairs.add(pair_id)\n",
    "        else:\n",
    "            cnt +=1\n",
    "            \n",
    "        points_list.append(point2)\n",
    "\n",
    "    # gdf = gpd.GeoDataFrame(geometry=points_list).set_crs(32718)\n",
    "    # gdf.to_file(f\"punkte_{route}.geojson\")\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame([\n",
    "    {'id_1': pair[0], 'id_2': pair[1], 'result': result}\n",
    "    for pair, result in results.items()\n",
    "])\n",
    "\n",
    "results_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb642d00-8942-4b72-8351-330d7f2fcab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
